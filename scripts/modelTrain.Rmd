## Model the `train` data

**Prototype with the `sample` data**

Select a subset of non-near-zero variance variables.

```{r}
sample <-
  select(sample, -matches(paste(nearzero$rowname, collapse = "|"))) %>%
  select(-matches("id"))
```

Register clusters.
Set the control parameters.

```{r}
cl <- makeCluster(10)
registerDoParallel(cl)
ctrl <- trainControl(method = "cv",
                     number = 10,
                     savePredictions = TRUE,
                     allowParallel = TRUE)
```


### Regression tree

Fit model over the tuning parameters.

```{r}
trainingModel <- train(loss ~ .,
                       data = sample,
                       method = "gbm",
                       trControl = ctrl)
stopCluster(cl)
```

Evaluate the model on the training dataset.

```{r}
trainingModel
hat <-
  sample %>%
  transform(hat = predict(trainingModel, .)) %>%
  select(matches("loss|hat"))
cor(hat[, c("loss", "hat")])
ggplot(hat, aes(x = loss, y = hat)) +
  scale_x_log10() +
  scale_y_log10() +
  stat_density_2d(aes(fill = ..level..), geom = "polygon") +
  scale_fill_gradient("density", low = "blue", high = "white") +
  geom_abline(intercept = 0, slope = 1) +
  labs(title = sprintf("Correlation = %.03g", cor(hat[, c("loss", "hat")])[1, 2])) +
  theme_bw()
```

Display the final model.

```{r}
varImp(trainingModel)
trainingModel$finalModel
```

Save the artifacts to file.

```{r}
save(trainingModel, hat, file = "../data/processed/trainingModel.RData")
```
